# lstm_bpm.py - BPM íšŒê·€ ëª¨ë¸ ì‹œìŠ¤í…œ
import os
import sys
# ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì–´ë–¤ ìœ„ì¹˜ì—ì„œ ì‹¤í–‰í•˜ë”ë¼ë„ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ import ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
# CuBLAS ê²°ì •ì  ë™ì‘ì„ ìœ„í•´ í™˜ê²½ë³€ìˆ˜ ì„¤ì • (torch/CUDA ì´ˆê¸°í™” ì´ì „)
os.environ.setdefault("CUBLAS_WORKSPACE_CONFIG", ":4096:8")
import numpy as np
import random
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import TensorDataset, DataLoader, Dataset, Sampler
from sklearn.model_selection import train_test_split
from helpers.func_plot import plot_training_curves, plot_test_results
from helpers.preproc_lstm import (
    extract_phase_derivative,
)
from helpers.preproc_signal import range_axis_m
from helpers.radar_config import FS_ADC, PAD_FT, B_HZ, NUM_SAMPLES, FRAME_REPETITION_TIME_S, FS_FRAME
from typing import Tuple, List, Optional, Dict

# ===== í•™ìŠµ íŒŒë¼ë¯¸í„° =====
EPOCHS = 1000                 # ì—í¬í¬
LEARNING_RATE = 1e-4  # í•™ìŠµë¥  ì¦ê°€ë¡œ ë‹¤ì–‘ì„± í–¥ìƒ          # ì§ì ‘ BPM ì˜ˆì¸¡ìš© ë‚®ì€ í•™ìŠµë¥  (ê³¼ì í•© ë°©ì§€)
HIDDEN_DIM = 128
NUM_LAYERS = 2                # LSTM ë ˆì´ì–´ 2ì¸µ ë° ë“œë¡­ì•„ì›ƒ ì ìš©

VALIDATION_SPLIT = 0.25       # ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ (20%ë¡œ ì¤„ì„)
EARLY_STOP_PATIENCE = 200     # ì–¼ë¦¬ ìŠ¤íƒ‘ ì¸ë‚´ì‹¬ (ì—í¬í¬) - ë” ì—¬ìœ ë¡­ê²Œ
EARLY_STOP_MIN_DELTA = 5e-5   # ìµœì†Œ ê°œì„  ì„ê³„ê°’ - ë” ê´€ëŒ€í•˜ê²Œ

# ===== ìŠ¤ì¼€ì¤„ëŸ¬ íŒŒë¼ë¯¸í„° =====
SCHEDULER_FACTOR = 0.5        # í•™ìŠµë¥  ê°ì†Œ ë¹„ìœ¨
SCHEDULER_PATIENCE = 25       # ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ë‚´ì‹¬ (ì—í¬í¬) - ë” ë¹ ë¥¸ í•™ìŠµë¥  ê°ì†Œ
SCHEDULER_MIN_LR = 5e-6       # ìµœì†Œ í•™ìŠµë¥ 

# ===== ì‹ í˜¸ ì²˜ë¦¬ íŒŒë¼ë¯¸í„° =====
FS          = FS_FRAME        # í”„ë ˆì„ë ˆì´íŠ¸ (Hz) - radar_configì—ì„œ ê°€ì ¸ì˜´
WIN_FRAMES  = int(8.0 * FS)   # 8ì´ˆ ìœˆë„ìš° = 288 í”„ë ˆì„
HOP_FRAMES  = int(0.5 * FS)   # 0.5ì´ˆ í™‰ = FS/2 í”„ë ˆì„
FMIN, FMAX  = 0.8, 3.0      # ì‹¬ë°• ëŒ€ì—­ [Hz] (48-180 BPMì— ëŒ€ì‘) - BPF ì ìš©
FEATURE_DIM = 18              # 1D CNNìœ¼ë¡œ ì••ì¶•í•  íŠ¹ì§• ì°¨ì› -> í™‰ìˆ˜

# ===== ë¶€ë“œëŸ¬ì›€ ì œì•½ íŒŒë¼ë¯¸í„° =====
SMOOTH_LAMBDA = 0.01           # ë¶€ë“œëŸ¬ì›€ ì œì•½ ê°•ë„ ë” ì¦ê°€ (ë°ì´í„° ì†ì‹¤ì˜ 5-10% ìˆ˜ì¤€ìœ¼ë¡œ)

# ===== ê²½ë¡œ ì„¤ì • =====
TRAIN_DATA_DIR = "record3/train/data/"
TRAIN_ANSWER_DIR = "record3/train/answer/"
TEST_DATA_DIR = "record3/test/data/"
TEST_ANSWER_DIR = "record3/test/answer/"

# ===== ì‹œë“œ ê³ ì • (ì¬í˜„ì„±) =====
seed = 42
os.environ["PYTHONHASHSEED"] = str(seed)
np.random.seed(seed)
random.seed(seed)
torch.manual_seed(seed)
if torch.cuda.is_available():
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
try:
    torch.use_deterministic_algorithms(True)
except Exception:
    pass
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# ===== ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ë“¤ (preproc_lstm.pyì—ì„œ import) =====
from helpers.preproc_lstm import (
    calculation, find_matching_files, load_ground_truth,
    create_bpm_labels, create_training_data,
    FileGroupedDataset, FileBatchSampler
)

# ===== 1D CNN + LSTM BPM íšŒê·€ ëª¨ë¸ ì •ì˜ =====
class BPMRegressionModel(nn.Module):
    """BPM ì˜ˆì¸¡ì„ ìœ„í•œ 1D CNN + LSTM íšŒê·€ ëª¨ë¸"""
    
    def __init__(self, input_dim: int = FEATURE_DIM, hidden: int = HIDDEN_DIM, num_layers: int = NUM_LAYERS):
        super().__init__()
        
        # 1D CNN: 7ì±„ë„ ì…ë ¥ (ë‹¤ì–‘í•œ ê´€ì ì˜ ì‹ í˜¸)
        self.conv1d = nn.Sequential(
                nn.Conv1d(7, 64, kernel_size=3, padding=1),  # 7ì±„ë„: dÏ†_BPF, dÏ†, H2_top1, SNR_hr, E_lo_norm, |z|_HPF, PSD_conf
                nn.ReLU(inplace=True),
                nn.AdaptiveAvgPool1d(1),   # (N,64,1)
                nn.Flatten(1),              # (N,64)
                nn.LayerNorm(64),   # â˜… í•œ ì¤„
            )
        
        # LSTM: ì‹œê³„ì—´ íŒ¨í„´ í•™ìŠµ
        self.lstm = nn.LSTM(
            input_size=64,  # ìœ„ìƒë¯¸ë¶„ë§Œ
            hidden_size=hidden,
            num_layers=num_layers,
            dropout=0.0 if num_layers == 1 else 0.3,  # ë‹¨ì¼ ë ˆì´ì–´ì—ì„œëŠ” dropout ë¹„í™œì„±í™”
            batch_first=True
        )
        
        # ===== ê·¼ë³¸ì  ë¬¸ì œ í•´ê²°: ëª¨ë¸ êµ¬ì¡° ë‹¨ìˆœí™” =====
        # íšŒê·€ í—¤ë“œ ë‹¨ìˆœí™” (ê³¼ì í•© ë°©ì§€, ì˜ˆì¸¡ ì•ˆì •ì„± í–¥ìƒ)
        # íšŒê·€: LSTM ì¶œë ¥ì„ BPMìœ¼ë¡œ ë³€í™˜ (í‰ê·  ìˆ˜ë ´ ë°©ì§€ìš© ë” í° ìš©ëŸ‰)
        self.regressor = nn.Sequential(
            nn.Linear(hidden, hidden // 2),  # 128 -> 64 (ë” í° ìš©ëŸ‰)
            nn.ReLU(),
            nn.Dropout(0.3),  # ë“œë¡­ì•„ì›ƒ ì¦ê°€ë¡œ ê³¼ì í•© ë°©ì§€
            nn.Linear(hidden // 2, hidden // 4),  # 64 -> 32
            nn.ReLU(),
            nn.Dropout(0.2),  # ë“œë¡­ì•„ì›ƒ ì¦ê°€
            nn.Linear(hidden // 4, 1),  # 32 -> 1 (BPM ê°’ ì§ì ‘ ì¶œë ¥)
        )
        
        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        self._initialize_weights()
        
        # ë§ˆì§€ë§‰ ë ˆì´ì–´ë¥¼ ë” í° ë²”ìœ„ë¡œ ì¬ì´ˆê¸°í™” (ë‹¤ì–‘ì„± ì¦ê°€)
        with torch.no_grad():
            self.regressor[-1].weight.normal_(0, 0.2)  # ê°€ì¤‘ì¹˜ ë¶„ì‚° ì¦ê°€
            self.regressor[-1].bias.normal_(0, 0.1)    # ë°”ì´ì–´ìŠ¤ë„ ëœë¤ ì´ˆê¸°í™”
        
        # ëª¨ë¸ êµ¬ì¡° ì¶œë ¥
        print(f"BPM íšŒê·€ ëª¨ë¸ êµ¬ì¡°:")
        print(f"  1D CNN: 7ì±„ë„({input_dim}) -> 64 (Conv1d 1ê°œ)")
        print(f"    ì±„ë„: [dÏ†_BPF, dÏ†, H2_top1, SNR_hr, E_lo_norm, |z|_HPF, PSD_conf]")
        print(f"  LSTM: 64 -> {hidden} (layers={num_layers})")
        print(f"  Regressor: {hidden} -> {hidden//2} -> {hidden//4} -> 1 (ê°•í™”ëœ BPM ì¶œë ¥)")
        
    def _initialize_weights(self):
        """ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
            elif isinstance(module, nn.Conv1d):
                nn.init.kaiming_normal_(module.weight, nonlinearity='relu')
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
            elif isinstance(module, nn.LSTM):
                for name, param in module.named_parameters():
                    if 'weight' in name:
                        nn.init.xavier_uniform_(param)
                    elif 'bias' in name:
                        nn.init.zeros_(param)
    
    def _calculate_train_labels_mean(self) -> float:
        """í›ˆë ¨ ë¼ë²¨ì˜ í‰ê· ê°’ì„ ê³„ì‚°í•˜ì—¬ ë°”ì´ì–´ìŠ¤ ì´ˆê¸°í™”ì— ì‚¬ìš©"""
        try:
            # í›ˆë ¨ ë°ì´í„° ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  ì •ë‹µ íŒŒì¼ì„ ì½ì–´ì„œ BPM í‰ê·  ê³„ì‚°
            train_answer_dir = TRAIN_ANSWER_DIR
            if not os.path.exists(train_answer_dir):
                print("[WARNING] í›ˆë ¨ ì •ë‹µ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 80.0 ì‚¬ìš©")
                return 80.0
            
            all_bpms = []
            answer_files = [f for f in os.listdir(train_answer_dir) if f.endswith('.csv')]
            
            for answer_file in answer_files:
                answer_path = os.path.join(train_answer_dir, answer_file)
                try:
                    gt_times = load_ground_truth(answer_path)
                    if gt_times is not None and len(gt_times) > 1:
                        # ì‹œê°„ ê°„ê²©ìœ¼ë¡œ BPM ê³„ì‚°
                        time_span = gt_times[-1] - gt_times[0]
                        if time_span > 0:
                            bpm = 60.0 * (len(gt_times) - 1) / time_span
                            if 30 <= bpm <= 200:  # ìœ íš¨í•œ BPM ë²”ìœ„
                                all_bpms.append(bpm)
                except Exception as e:
                    raise e
            
            if all_bpms:
                mean_bpm = np.mean(all_bpms)
                print(f"[INFO] í›ˆë ¨ ë¼ë²¨ í‰ê·  ê³„ì‚° ì™„ë£Œ: {len(all_bpms)}ê°œ íŒŒì¼, í‰ê·  BPM: {mean_bpm:.2f}")
                return float(mean_bpm)
            else:
                raise ValueError("ìœ íš¨í•œ BPM ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            raise e

    def forward(self, x: torch.Tensor, hidden: Optional[Tuple] = None) -> Tuple[torch.Tensor, Tuple]:
        """
        Args:
            x: (batch, seq_len, 7, feat_dim) - 7ì±„ë„: [dÏ†_BPF, dÏ†, H2_top1, SNR_hr, E_lo_norm, |z|_HPF, PSD_conf]
            hidden: LSTM hidden state
        Returns:
            bpm_pred: (batch, 1) - ì˜ˆì¸¡ëœ BPM ê°’
            hidden: ì—…ë°ì´íŠ¸ëœ hidden state
        """
        # # x: (B, T, F)
        # mu  = x.mean(dim=1, keepdim=True)                 # (B, 1, F)  ì‹œê°„ í‰ê· 
        # std = x.std(dim=1, keepdim=True) + 1e-6           # (B, 1, F)
        # x = (x - mu) / std                                # (B, T, F)

        batch_size, seq_len, channels, feat_dim = x.shape  # (batch, seq_len, 6, feat_dim)
        
        # 1D CNN ì ìš©ì„ ìœ„í•´ ì°¨ì› ì¬ë°°ì—´: (batch, seq_len, 6, feat_dim) -> (batch * seq_len, 6, feat_dim)
        x_reshaped = x.view(-1, channels, feat_dim)
        # 1D CNN íŠ¹ì§• ì¶”ì¶œ: (batch * seq_len, 6, feat_dim) -> (batch * seq_len, 64, 1)
        conv_out = self.conv1d(x_reshaped)
        # LSTM ì…ë ¥ì„ ìœ„í•´ ì°¨ì› ì¬ë°°ì—´: (batch * seq_len, 64, 1) -> (batch, seq_len, 64)
        conv_out = conv_out.view(batch_size, seq_len, 64)
        
        # LSTM ì²˜ë¦¬
        lstm_out, hidden = self.lstm(conv_out, hidden)

        # ê°€ì¤‘ í‰ê·  (ê¶Œì¥, ë¼ë²¨ê³¼ ì •í™•íˆ ì¼ì¹˜)
        step_sec = HOP_FRAMES / FS                    # 0.5s
        M = max(1, int(round(3.0 / step_sec)))        # ë¼ë²¨ ì°½ 3.0ì´ˆì— í•´ë‹¹í•˜ëŠ” 0.5ì´ˆì— í•´ë‹¹í•˜ëŠ” ìŠ¤í… ìˆ˜ (Hop=0.5s â†’ 6)
        M = min(M, lstm_out.size(1))

        sel = lstm_out[:, -M:, :]                     # (B, M, H)
        # ë’¤ë¡œ ê°ˆìˆ˜ë¡(ë¼ë²¨ ëì— ê°€ê¹Œìš¸ìˆ˜ë¡) ì¡°ê¸ˆ ë” ê°€ì¤‘
        weights = torch.arange(1, M + 1, device=lstm_out.device, dtype=lstm_out.dtype)
        weights = weights / weights.sum()
        last_output = (sel * weights.view(1, M, 1)).sum(dim=1)  # (B, H)
        # w = torch.tensor([0.2, 0.3, 0.5], device=lstm_out.device)
        # last_output = (lstm_out[:, -3:, :] * w.view(1, 3, 1)).sum(dim=1)
        
        # ì§ì ‘ BPM íšŒê·€ (ì„ í˜• ì¶œë ¥, í´ë¦¬í•‘ ì œê±°)
        bpm_pred = self.regressor(last_output)  # (batch, 1)
        
        return bpm_pred, hidden

# ===== BPM ì˜ˆì¸¡ ì‹œìŠ¤í…œ =====
class BPMPredictor:
    """ë””ë ‰í„°ë¦¬ ê¸°ë°˜ BPM íšŒê·€ ì˜ˆì¸¡ ì‹œìŠ¤í…œ"""
    
    def __init__(self, train_data_dir: str, train_answer_dir: str):
        """
        Args:
            train_data_dir: í•™ìŠµ ë°ì´í„° í´ë” ê²½ë¡œ
            train_answer_dir: í•™ìŠµ ì •ë‹µ í´ë” ê²½ë¡œ
        """
        self.train_data_dir = train_data_dir
        self.train_answer_dir = train_answer_dir
        self.model = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        # ë¼ë²¨ ì •ê·œí™” í†µê³„ (í›ˆë ¨ ì‹œ ê³„ì‚°)
        self.label_mean: Optional[float] = None
        self.label_std: Optional[float] = None
        print(f"ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"í•™ìŠµ ë°ì´í„° ê²½ë¡œ: {train_data_dir}")
        print(f"í•™ìŠµ ì •ë‹µ ê²½ë¡œ: {train_answer_dir}")

    def _apply_pre_filtering(self, signal_for_psd: np.ndarray, signal_for_notch: np.ndarray, fs: float) -> np.ndarray:
        """í”„ë¦¬í•„í„°ë§: ì´ìƒì¹˜ ì£¼íŒŒìˆ˜ notch ì œê±° (ì•ˆì •ì„± ê°œì„  ë²„ì „)

        Args:
            signal_for_psd: HPFë§Œ ì ìš©í•œ dÏ† ì‹ í˜¸ (PSD ê²€ì¶œìš©)
            signal_for_notch: BPF ì ìš©ëœ dÏ† ì‹ í˜¸ (notch ì ìš©ìš©)
            fs: ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜

        Welch PSDë¡œ HR ëŒ€ì—­ ì´ìƒì¹˜ íƒì§€ í›„ ì„ íƒì  notch ì ìš©:
        - 4ì´ˆ ì„¸ê·¸ë¨¼íŠ¸, 75% overlap (í•´ìƒë„ 0.25Hz)
        - ë¡œì»¬ median ëŒ€ë¹„ z-score > 6.0 (ë³´ìˆ˜ì )
        - ì—°ì† 2ê°œ ì´ìƒ ì§€ì†ë˜ëŠ” ì´ìƒì¹˜ë§Œ ì„ íƒ
        - ìµœê°• HR í”¼í¬ 1ê°œ ì£¼ë³€ Â±0.20Hz ë³´í˜¸ (ì •êµ)
        - ìµœëŒ€ 1ê°œ ì£¼íŒŒìˆ˜ì— notch (Q=30, íš¨ê³¼ì ì´ë©´ 2ê°œê¹Œì§€)
        """
        try:
            from scipy.signal import welch, iirnotch, tf2sos, sosfiltfilt
            from scipy.ndimage import median_filter

            # Welch PSD ê³„ì‚° (4ì´ˆ ì„¸ê·¸ë¨¼íŠ¸, 75% overlap, í•´ìƒë„ 0.25Hz)
            nperseg = min(int(4.0 * fs), len(signal_for_psd))  # 4ì´ˆ ì„¸ê·¸ë¨¼íŠ¸ (ì•ˆì „í•˜ê²Œ ê¸¸ì´ ì œí•œ)
            noverlap = int(0.75 * nperseg)  # 75% overlap

            f, Pxx = welch(signal_for_psd, fs=fs, window='hann',
                          nperseg=nperseg, noverlap=noverlap,
                          detrend='constant', scaling='density')

            # HR ëŒ€ì—­ ì¶”ì¶œ (0.8-3 Hz)
            hr_mask = (f >= 0.8) & (f <= 3.0)
            f_hr = f[hr_mask]
            P_hr = Pxx[hr_mask]

            if len(P_hr) == 0:
                raise ValueError("HR ëŒ€ì—­ ë°ì´í„° ì—†ìŒ")

            # ì´ìƒì¹˜ íƒì§€ (ë¡œì»¬ median ëŒ€ë¹„ z-score/MAD)
            bg = median_filter(P_hr, size=min(5, len(P_hr)), mode='nearest')
            mad = np.median(np.abs(P_hr - bg)) + 1e-9
            z_scores = (P_hr - bg) / mad

            # ì´ìƒì¹˜ ì¡°ê±´: z-score > 6.0, ì—°ì† 2ê°œ ì´ìƒ (ë³´ìˆ˜ì )
            outlier_mask = z_scores > 6.0

            # ì—°ì†ì„± ì²´í¬ (2ê°œ ì´ìƒ ì—°ì†)
            consecutive_count = 0
            sustained_outliers = []

            for i, is_outlier in enumerate(outlier_mask):
                if is_outlier:
                    consecutive_count += 1
                else:
                    if consecutive_count >= 2:  # 2ê°œ ì´ìƒ ì—°ì†
                        sustained_outliers.extend(range(i - consecutive_count, i))
                    consecutive_count = 0

            # ë§ˆì§€ë§‰ ê·¸ë£¹ ì²˜ë¦¬
            if consecutive_count >= 2:
                sustained_outliers.extend(range(len(outlier_mask) - consecutive_count, len(outlier_mask)))

            # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
            sustained_outliers = sorted(list(set(sustained_outliers)))

            # í”¼í¬ ë³´í˜¸: ìµœê°• HR í”¼í¬ 1ê°œ ì£¼ë³€ Â±0.20Hz ë³´í˜¸ (ì •êµ)
            protect_mask = np.zeros(len(f_hr), dtype=bool)
            if len(P_hr) > 0:
                # ìµœê°• í”¼í¬ 1ê°œë§Œ ë³´í˜¸ (ê°€ì¥ í° 1ê°œ)
                peak_idx = np.argmax(P_hr)
                peak_freq = f_hr[peak_idx]
                # í”¼í¬ ì£¼ë³€ Â±0.20 Hz ë³´í˜¸
                peak_protect = (f_hr >= peak_freq - 0.20) & (f_hr <= peak_freq + 0.20)
                protect_mask |= peak_protect

            # ë³´í˜¸ êµ¬ê°„ ì œì™¸
            sustained_outliers = [idx for idx in sustained_outliers if not protect_mask[idx]]

            # ê°œìˆ˜ ì œí•œ: ìµœëŒ€ 1ê°œ notch (íš¨ê³¼ì ì´ë©´ 2ê°œê¹Œì§€ í—ˆìš©)
            sustained_outliers = sustained_outliers[:1]  # ê¸°ë³¸ 1ê°œ, íš¨ê³¼ì ì´ë©´ 2ê°œê¹Œì§€

            # notch ì ìš© (signal_for_notchì— ì ìš©)
            filtered_signal = signal_for_notch.copy()
            for idx in sustained_outliers:
                notch_freq = f_hr[idx]
                w0 = notch_freq / (fs / 2.0)  # ì •ê·œí™”ëœ ì£¼íŒŒìˆ˜

                # IIR notch í•„í„° (Q=30ìœ¼ë¡œ ì¢ê²Œ)
                b, a = iirnotch(w0, Q=30.0)
                sos = tf2sos(b, a)

                # ì˜¤í”„ë¼ì¸ í•„í„°ë§ (sosfiltfilt)
                filtered_signal = sosfiltfilt(sos, filtered_signal)

            return filtered_signal

        except Exception as e:
            print(f"í”„ë¦¬í•„í„°ë§ ì—ëŸ¬: {e}")
            return signal_for_notch  # ì—ëŸ¬ì‹œ ì›ë³¸ ë°˜í™˜

    def _compute_psd_confidence(self, signal_segment: np.ndarray, fs: float) -> float:
        """PSD ê¸°ë°˜ ì‹ í˜¸ ì‹ ë¢°ë„ ê³„ì‚° (í”„ë¦¬í•„í„°ë§ ì ìš©ëœ ì„¸ê·¸ë¨¼íŠ¸ìš©)

        Args:
            signal_segment: 0.5ì´ˆ ì„¸ê·¸ë¨¼íŠ¸ ì‹ í˜¸ (dphi_bp_segment)
            fs: ìƒ˜í”Œë§ ì£¼íŒŒìˆ˜

        Returns:
            confidence: 0-1 ì‚¬ì´ ì‹ ë¢°ë„ (1 = ê³ í’ˆì§ˆ HR ì‹ í˜¸)
        """
        try:
            from scipy.signal import welch

            # ì„¸ê·¸ë¨¼íŠ¸ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
            if len(signal_segment) < 32:  # ìµœì†Œ 32ìƒ˜í”Œ
                return 0.5

            # Welch PSD ê³„ì‚° (ì„¸ê·¸ë¨¼íŠ¸ í¬ê¸°ì— ë§ê²Œ)
            nperseg = min(64, len(signal_segment))  # ìµœëŒ€ 64ìƒ˜í”Œ ì„¸ê·¸ë¨¼íŠ¸
            noverlap = nperseg // 2  # 50% overlap

            f, Pxx = welch(signal_segment, fs=fs, window='hann',
                          nperseg=nperseg, noverlap=noverlap,
                          detrend='constant', scaling='density')

            # HR ëŒ€ì—­ (0.8-3 Hz) ì¶”ì¶œ
            hr_mask = (f >= 0.8) & (f <= 3.0)
            if not np.any(hr_mask):
                return 0.3  # HR ëŒ€ì—­ ì—†ìŒ

            f_hr = f[hr_mask]
            P_hr = Pxx[hr_mask]

            # ì‹ ë¢°ë„ ê³„ì‚° ì§€í‘œë“¤
            if len(P_hr) > 0:
                # 1. HR ëŒ€ì—­ í”¼í¬ ê°•ë„ (ì „ì²´ íŒŒì›Œ ëŒ€ë¹„)
                hr_power = np.sum(P_hr)
                total_power = np.sum(Pxx) + 1e-10
                hr_ratio = hr_power / total_power

                # 2. í”¼í¬ ë‚ ì¹´ë¡œì›€ (ìµœëŒ€/í‰ê·  ë¹„ìœ¨)
                peak_sharpness = np.max(P_hr) / (np.mean(P_hr) + 1e-10)

                # 3. ì¡ìŒ ë°”ë‹¥ ë ˆë²¨ (í•˜ìœ„ 25% ë¶„ìœ„ìˆ˜)
                noise_floor = np.percentile(P_hr, 25)

                # ì¢…í•© ì‹ ë¢°ë„ (0-1 ìŠ¤ì¼€ì¼)
                confidence = hr_ratio * np.tanh(peak_sharpness / 10.0) * (1.0 - noise_floor / (np.max(P_hr) + 1e-10))

                # ë²”ìœ„ ì œí•œ
                confidence = np.clip(confidence, 0.0, 1.0)

                return float(confidence)
            else:
                return 0.3

        except Exception as e:
            print(f"PSD ì‹ ë¢°ë„ ê³„ì‚° ì—ëŸ¬: {e}")
            return 0.5  # ì¤‘ê°„ê°’ ë°˜í™˜

    def load_all_training_data(self) -> Tuple[List[np.ndarray], List[np.ndarray]]:
        """ëª¨ë“  í•™ìŠµ íŒŒì¼ ë¡œë”©"""
        pairs = find_matching_files(self.train_data_dir, self.train_answer_dir)
        
        if not pairs:
            raise FileNotFoundError("í•™ìŠµ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"=== ë‹¤ì¤‘ íŒŒì¼ ë°ì´í„° ë¡œë”© ===")
        print(f"í•™ìŠµ ë°ì´í„° {len(pairs)}ê°œ íŒŒì¼ ë°œê²¬:")
        all_z_tau = []
        all_gt_times = []
        
        for i, (data_path, answer_path) in enumerate(pairs):
            file_num = os.path.splitext(os.path.basename(data_path))[0]
            print(f"  {i+1}. íŒŒì¼ {file_num}: {data_path}")
            
            # ë°ì´í„° ë¡œë”©
            fc_bin, z_tau = calculation(data_path, FS_ADC, NUM_SAMPLES, PAD_FT, B_HZ)
            gt_times = load_ground_truth(answer_path)
            
            if gt_times is not None:
                all_z_tau.append(z_tau)
                all_gt_times.append(gt_times)
                avg_bpm = 60.0 * len(gt_times) / (gt_times[-1] - gt_times[0])
                print(f"     - ê±°ë¦¬ bin: {fc_bin}, ë¹„íŠ¸: {len(gt_times)}ê°œ, í‰ê·  BPM: {avg_bpm:.1f}")
            else:
                print(f"     - âš ï¸ ì •ë‹µ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨")
        
        print(f"ì´ {len(all_z_tau)}ê°œ íŒŒì¼ ë¡œë”© ì™„ë£Œ")
        
        # BPM ë¶„í¬ ë¶„ì„
        all_bpms = []
        for gt_times in all_gt_times:
            if len(gt_times) > 1:
                avg_bpm = 60.0 * len(gt_times) / (gt_times[-1] - gt_times[0])
                all_bpms.append(avg_bpm)
        
        if all_bpms:
            print(f"\n=== í•™ìŠµ ë°ì´í„° BPM ë¶„í¬ ===")
            print(f"í‰ê· : {np.mean(all_bpms):.1f} BPM")
            print(f"ë²”ìœ„: {np.min(all_bpms):.1f} - {np.max(all_bpms):.1f} BPM")
            print(f"í‘œì¤€í¸ì°¨: {np.std(all_bpms):.1f} BPM")

            # BPM ë¶„í¬ ë¶„ì„ (ê·¼ë³¸ì  ë¬¸ì œ ì§„ë‹¨)
            bpm_counts, bpm_bins = np.histogram(all_bpms, bins=10)
            print(f"BPM íˆìŠ¤í† ê·¸ë¨:")
            for i in range(len(bpm_counts)):
                bin_start = bpm_bins[i]
                bin_end = bpm_bins[i+1]
                count = bpm_counts[i]
                print(f"  {bin_start:.0f}-{bin_end:.0f} BPM: {count}ê°œ")

            # ë°ì´í„° í’ˆì§ˆ ì§€í‘œ
            print(f"\në°ì´í„° í’ˆì§ˆ ì§€í‘œ:")
            print(f"- ì´ ìƒ˜í”Œ ìˆ˜: {len(all_bpms)}")
            print(f"- IBI ë²”ìœ„ ë‚´ ìƒ˜í”Œ ë¹„ìœ¨: {(len(all_bpms)/len(all_bpms))*100:.1f}%")  # ë¼ë²¨ ë…¸ì´ì¦ˆ ê²Œì´íŠ¸ í›„
            print(f"- BPM ë³€ë™ì„±: {(np.std(all_bpms)/np.mean(all_bpms))*100:.1f}% CV")
            
        return all_z_tau, all_gt_times
    
    def process_window(self, window: np.ndarray) -> np.ndarray:
        """8ì´ˆ ìœˆë„ìš°ë¥¼ 8ê°œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ìœ„ìƒë¯¸ë¶„ ì‹ í˜¸ë¥¼ ì§ì ‘ ì‚¬ìš© (ê°œì„ ëœ ì‹ í˜¸ ì²˜ë¦¬ ìˆœì„œ)"""
        
        # ===== ê°œì„ ëœ ì‹ í˜¸ ì²˜ë¦¬ ìˆœì„œ =====
        # Before: z_tau(ë³µì†Œ) â†’ BPF(0.8-3 Hz) â†’ angle() â†’ unwrap() â†’ ë¯¸ë¶„
        # After:  z_tau(ë³µì†Œ) â†’ angle() â†’ unwrap() â†’ HPF(0.3 Hz) â†’ ë¯¸ë¶„ â†’ BPF(0.8-3 Hz)
        
        try:
            # 1ë‹¨ê³„: ë³µì†Œ ì‹ í˜¸ì—ì„œ ìœ„ìƒ ì¶”ì¶œ (HPF ì „ì²˜ë¦¬ë§Œ, ì •ê·œí™”ëŠ” 1ì´ˆ êµ¬ê°„ë³„ë¡œ)
            dphi_full = extract_phase_derivative(window, FS, apply_hpf=True, hpf_freq=0.3, normalize=False)
            
            # 2ë‹¨ê³„: ìœ„ìƒ ì‹ í˜¸ì— BPF(0.8-3 Hz) ì ìš©
            from scipy.signal import butter, sosfiltfilt, welch, iirnotch, tf2sos
            from scipy.ndimage import median_filter
            from helpers.preproc_lstm import compute_harmonic_features, compute_energy_features
            
            low_freq = FMIN   # Hz (48 BPM)
            high_freq = FMAX  # Hz (180 BPM)
            nyquist = FS / 2.0
            low_norm = low_freq / nyquist
            high_norm = high_freq / nyquist
            
            # 2ì°¨ Butterworth BPF ê³„ìˆ˜ ê³„ì‚° (SOS í˜•íƒœ)
            sos_bpf = butter(2, [low_norm, high_norm], btype='band', output='sos')
            dphi_bp = sosfiltfilt(sos_bpf, dphi_full, padtype='odd')

            # 2.5ë‹¨ê³„: í”„ë¦¬í•„í„°ë§ (ì´ìƒì¹˜ ì£¼íŒŒìˆ˜ notch ì œê±°)
            # PSD ê²€ì¶œì€ HPFë§Œ ì ìš©í•œ dphi_fullë¡œ, notch ì ìš©ì€ dphi_bpì—
            dphi_bp = self._apply_pre_filtering(dphi_full, dphi_bp, FS)
            
            # ë³µì†Œ ì‹ í˜¸ í¬ê¸° ì¶”ì¶œ (|z|_HPF) - ë‚´ì¥ íŒ¨ë”© ì‚¬ìš©
            z_magnitude = np.abs(window)
            
            # HPF ì„¤ê³„ (2ì°¨ Butterworth, 0.3 Hz)
            hpf_freq = 0.3  # Hz
            hpf_norm = hpf_freq / nyquist
            sos_hpf = butter(2, hpf_norm, btype='high', output='sos')
            
            # HPF ì ìš© (í¬ê¸°ì—) - ë‚´ì¥ íŒ¨ë”© ì‚¬ìš©
            z_magnitude_hpf = sosfiltfilt(sos_hpf, z_magnitude, padtype='odd')
            
            # 3ë‹¨ê³„: 8ì´ˆ ì „ì²´ì—ì„œ í•˜ëª¨ë‹‰/ì—ë„ˆì§€ í”¼ì²˜ 1íšŒ ê³„ì‚°
            h2_top1, h2_top2 = compute_harmonic_features(dphi_bp, dphi_full, FS)
            E_lo_norm, SNR_hr = compute_energy_features(dphi_bp, FS)
            
            # 4ë‹¨ê³„: 6ì±„ë„ ì…ë ¥ ìƒì„± [dÏ†_BPF, dÏ†, H2_top1, SNR_hr, E_lo_norm, |z|_HPF]
            sub_intervals = WIN_FRAMES // HOP_FRAMES  # 16ê°œ êµ¬ê°„
            sub_window_size = HOP_FRAMES              # 18í”„ë ˆì„ = 0.5ì´ˆ
            sub_features = []
            
            # 3ì´ˆ ë¡¤ë§ ì»¨í…ìŠ¤íŠ¸ ì •ê·œí™” (ë¼ë²¨ ì°½ê³¼ ë™ê¸°í™”)
            span = int(round(3.0 * FS))  # 3ì´ˆ = 108í”„ë ˆì„
            
            # 3ì´ˆ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ Robust ì •ê·œí™” í•¨ìˆ˜
            def rznorm_ctx(x, ctx):
                med = np.median(ctx)
                mad = np.median(np.abs(ctx - med)) + 1e-6
                return (x - med) / mad
            
            for i in range(sub_intervals):
                start_idx = i * sub_window_size
                end_idx = (i + 1) * sub_window_size if i < sub_intervals - 1 else len(dphi_bp)
                
                # 3ì´ˆ ë¡¤ë§ ì»¨í…ìŠ¤íŠ¸ (ì§ì „ 3ì´ˆ êµ¬ê°„)
                ctx_start = max(0, end_idx - span)
                ctx_slice_bp = dphi_bp[ctx_start:end_idx]
                ctx_slice_dph = dphi_full[ctx_start:end_idx]
                ctx_slice_mag = z_magnitude_hpf[ctx_start:end_idx]
                
                # ê° êµ¬ê°„ì—ì„œ 6ì±„ë„ ì¶”ì¶œ ë° 3ì´ˆ ì»¨í…ìŠ¤íŠ¸ ì •ê·œí™”
                dphi_bp_segment = dphi_bp[start_idx:end_idx]
                dphi_segment = dphi_full[start_idx:end_idx]
                z_mag_segment = z_magnitude_hpf[start_idx:end_idx]
                
                # 3ì´ˆ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ Robust ì •ê·œí™”
                dphi_bp_segment = rznorm_ctx(dphi_bp_segment, ctx_slice_bp)
                dphi_segment = rznorm_ctx(dphi_segment, ctx_slice_dph)
                z_mag_segment = rznorm_ctx(z_mag_segment, ctx_slice_mag)
                
                if (len(dphi_bp_segment) == FEATURE_DIM and 
                    len(dphi_segment) == FEATURE_DIM and 
                    len(z_mag_segment) == FEATURE_DIM):
                    
                    # 7ì±„ë„ ìŠ¤íƒ: [dÏ†_BPF, dÏ†, H2_top1, SNR_hr, E_lo_norm, |z|_HPF, PSD_conf]
                    # ì „ì—­ íŠ¹ì„±ë“¤ì„ ì‹œê°„ì¶•ì— ë”°ë¼ ì•½ê°„ì˜ ë³€ë™ ì¶”ê°€ (í‘œì¤€í¸ì°¨ 0 ë°©ì§€)
                    h2_top1_channel = np.full(FEATURE_DIM, h2_top1, dtype=np.float32)
                    h2_top1_channel += np.random.normal(0, 0.01, FEATURE_DIM).astype(np.float32)  # ì‘ì€ ë…¸ì´ì¦ˆ ì¶”ê°€
                    
                    snr_hr_channel = np.full(FEATURE_DIM, SNR_hr, dtype=np.float32)
                    snr_hr_channel += np.random.normal(0, 0.01, FEATURE_DIM).astype(np.float32)  # ì‘ì€ ë…¸ì´ì¦ˆ ì¶”ê°€
                    
                    e_lo_norm_channel = np.full(FEATURE_DIM, E_lo_norm, dtype=np.float32)
                    e_lo_norm_channel += np.random.normal(0, 0.01, FEATURE_DIM).astype(np.float32)  # ì‘ì€ ë…¸ì´ì¦ˆ ì¶”ê°€

                    # PSD ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚° (ì§ì „ 3ì´ˆ ì»¨í…ìŠ¤íŠ¸ë¡œ ê³„ì‚°)
                    psd_confidence = self._compute_psd_confidence(ctx_slice_bp, FS)
                    psd_conf_channel = np.full(FEATURE_DIM, psd_confidence, dtype=np.float32)
                    psd_conf_channel += np.random.normal(0, 0.01, FEATURE_DIM).astype(np.float32)  # ì‘ì€ ë…¸ì´ì¦ˆ ì¶”ê°€

                    seven_channel = np.stack([
                        dphi_bp_segment,      # ì±„ë„ 0: dÏ†_BPF (3ì´ˆ ì»¨í…ìŠ¤íŠ¸ ì •ê·œí™”)
                        dphi_segment,         # ì±„ë„ 1: dÏ† (3ì´ˆ ì»¨í…ìŠ¤íŠ¸ ì •ê·œí™”)
                        h2_top1_channel,      # ì±„ë„ 2: H2_top1 (8ì´ˆ ì „ì²´ì—ì„œ ê³„ì‚°)
                        snr_hr_channel,       # ì±„ë„ 3: SNR_hr (8ì´ˆ ì „ì²´ì—ì„œ ê³„ì‚°)
                        e_lo_norm_channel,    # ì±„ë„ 4: E_lo_norm (8ì´ˆ ì „ì²´ì—ì„œ ê³„ì‚°)
                        z_mag_segment,        # ì±„ë„ 5: |z|_HPF (3ì´ˆ ì»¨í…ìŠ¤íŠ¸ ì •ê·œí™”)
                        psd_conf_channel      # ì±„ë„ 6: PSD_conf (í”„ë¦¬í•„í„°ë§ ì‹ ë¢°ë„)
                    ], axis=0)
                    
                    sub_features.append(seven_channel.astype(np.float32))
                else:
                    print(f"ìœ„ìƒë¯¸ë¶„ êµ¬ê°„ í¬ê¸° ë¶ˆì¼ì¹˜: {len(dphi_bp_segment)} != {FEATURE_DIM}")
                    raise ValueError(f"ìœ„ìƒë¯¸ë¶„ êµ¬ê°„ í¬ê¸° ë¶ˆì¼ì¹˜: {len(dphi_bp_segment)} != {FEATURE_DIM}")

        except Exception as e:
            print(f"ìœ„ìƒë¯¸ë¶„ ì¶”ì¶œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
            raise e
        
        # (16, 6, FEATURE_DIM)ìœ¼ë¡œ ê²°í•©
        feats = np.array(sub_features, dtype=np.float32)  # (16, 6, 36)
        # 3ì´ˆ ë¡¤ë§ ì»¨í…ìŠ¤íŠ¸ ì •ê·œí™”ë¡œ ë¼ë²¨ ì°½ê³¼ ë™ê¸°í™”, í•˜ëª¨ë‹‰/ì—ë„ˆì§€ í”¼ì²˜ëŠ” 8ì´ˆ ì „ì²´ì—ì„œ 1íšŒ ê³„ì‚°
        return feats
    
    def train_on_multiple_files(self, all_z_tau: List[np.ndarray], all_gt_times: List[np.ndarray], batch_size: int):
        """ì—¬ëŸ¬ íŒŒì¼ë¡œ DataLoader ë°°ì¹˜ í•™ìŠµ (ê²€ì¦ ë° ì–¼ë¦¬ ìŠ¤íƒ‘ í¬í•¨)"""
        # ===== 4) ì…ë ¥ íŠ¹ì„±(ì „ì²˜ë¦¬) ì ê²€ =====
        first_features = self.process_window(all_z_tau[0][:WIN_FRAMES])
        print(f"íŠ¹ì§• ì°¨ì›: {first_features.shape}")

        # ì…ë ¥ íŠ¹ì„± ë¶„í¬ ë¶„ì„
        f = first_features  # numpy array
        print("=== ì…ë ¥ íŠ¹ì„± ë¶„ì„ ===")
        print(f"first_features shape: {f.shape}")
        print(f"global mean/std: {f.mean():.4f}, {f.std():.4f}")
        print(f"min/max: {f.min():.4f}, {f.max():.4f}")

        # ì±„ë„ë³„ ë¶„í¬ ë¶„ì„ (7ê°œ ì±„ë„)
        for ch in range(f.shape[1]):
            ch_mean = f[:, ch, :].mean()
            ch_std = f[:, ch, :].std()
            print(f"ch{ch} mean/std: {ch_mean:.4f}, {ch_std:.4f}")
        
        self.model = BPMRegressionModel(input_dim=FEATURE_DIM).to(self.device)
        print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in self.model.parameters()):,}")
        
        # íŒŒë¼ë¯¸í„° ê·¸ë£¹: ë§ˆì§€ë§‰ íšŒê·€ ë ˆì´ì–´ì— ë” í° í•™ìŠµë¥  (í•­ë“±ì„±ìœ¼ë¡œ ë¶„ë¦¬)
        last_layer_params = list(self.model.regressor[-1].parameters())
        last_param_ids = {id(p) for p in last_layer_params}
        other_params = [p for p in self.model.parameters() if id(p) not in last_param_ids]
        optimizer = torch.optim.Adam([
            {"params": other_params, "lr": LEARNING_RATE},
            {"params": last_layer_params, "lr": LEARNING_RATE},
        ])
        
        # í•™ìŠµ/ê²€ì¦ ë°ì´í„° ìƒì„± ë° DataLoader ì„¤ì •
        (X_train, y_train, X_val, y_val,
         train_file_features, train_file_labels,
         val_file_features, val_file_labels) = create_training_data(
            all_z_tau, all_gt_times, self, WIN_FRAMES, HOP_FRAMES,
            FRAME_REPETITION_TIME_S, VALIDATION_SPLIT
        )
        
        # ë¼ë²¨ ì •ê·œí™” í†µê³„ ê³„ì‚° í›„ Huber Lossì˜ beta ì¡°ì •
        beta_bpm = 3.0                             # 2~4 BPM ì¤‘ í•˜ë‚˜ë¡œ íŠœë‹
        beta_std = beta_bpm / self.label_std        # z-ìŠ¤ì¼€ì¼ ì„ê³„ì¹˜
        
        # criterion ê°ì²´ëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (F.smooth_l1_loss ì§ì ‘ í˜¸ì¶œ)
        print(f"Huber Loss beta ì¡°ì •: {beta_bpm} BPM -> {beta_std:.3f} (z-scale)")
        print(f"SmoothL1Loss ì§ì ‘ í˜¸ì¶œë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ê²½ê³  ì œê±°")
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ê°€ (ê²€ì¦ ì†ì‹¤ ê¸°ë°˜)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer,
            mode='min',           # ê²€ì¦ ì†ì‹¤ ìµœì†Œí™”
            factor=SCHEDULER_FACTOR,  # í•™ìŠµë¥  ê°ì†Œ ë¹„ìœ¨
            patience=SCHEDULER_PATIENCE,  # ì¸ë‚´ì‹¬
            min_lr=SCHEDULER_MIN_LR,     # ìµœì†Œ í•™ìŠµë¥ 
        )

        print(f"\n=== ë°°ì¹˜ í•™ìŠµ ì‹œì‘ (ì—í¬í¬: {EPOCHS}, ë°°ì¹˜í¬ê¸°: {batch_size}) ===")
        print(f"ê²€ì¦ ë°ì´í„° ë¹„ìœ¨: {VALIDATION_SPLIT*100:.0f}%, ì–¼ë¦¬ ìŠ¤íƒ‘ ì¸ë‚´ì‹¬: {EARLY_STOP_PATIENCE} ì—í¬í¬")
        print(f"ìŠ¤ì¼€ì¤„ëŸ¬: ReduceLROnPlateau (factor={SCHEDULER_FACTOR}, patience={SCHEDULER_PATIENCE})")
        
        # ===== íŒŒì¼ë³„ ê·¸ë£¹í™”ëœ ë°ì´í„°ì…‹ ìƒì„± (ë¶€ë“œëŸ¬ì›€ ì œì•½ìš©) =====
        train_grouped_dataset = FileGroupedDataset(train_file_features, train_file_labels)
        val_grouped_dataset = FileGroupedDataset(val_file_features, val_file_labels)

        # íŒŒì¼ë³„ ë°°ì¹˜ ìƒ˜í”ŒëŸ¬ ìƒì„± (ê° ë°°ì¹˜ê°€ ë™ì¼ íŒŒì¼ì˜ ì—°ì† ìƒ˜í”Œë§Œ í¬í•¨)
        train_sampler = FileBatchSampler(
            file_lengths=train_grouped_dataset.file_lengths,
            batch_size=batch_size,
            drop_last=False,
            shuffle_files=True,  # íŒŒì¼ ìˆœì„œë§Œ ëœë¤í•˜ê²Œ ì„ìŒ
            seed=42
        )

        val_sampler = FileBatchSampler(
            file_lengths=val_grouped_dataset.file_lengths,
            batch_size=batch_size,
            drop_last=False,
            shuffle_files=True,  # ê²€ì¦ì—ì„œë„ íŒŒì¼ ìˆœì„œ ëœë¤í™”
            seed=42
        )

        train_dataloader = DataLoader(
            train_grouped_dataset,
            batch_sampler=train_sampler,  # batch_sampler ì‚¬ìš©
            num_workers=0,  # Windowsì—ì„œ ì•ˆì •ì 
            pin_memory=torch.cuda.is_available()
        )

        val_dataloader = DataLoader(
            val_grouped_dataset,
            batch_sampler=val_sampler,  # batch_sampler ì‚¬ìš©
            num_workers=0,
            pin_memory=torch.cuda.is_available()
        )
        
        print(f"DataLoader ìƒì„±: í›ˆë ¨ {len(train_grouped_dataset)}ê°œ, ê²€ì¦ {len(val_grouped_dataset)}ê°œ ìœˆë„ìš°")
        print(f"íŒŒì¼ë³„ ë°°ì¹˜ ìƒì„±: í›ˆë ¨ {len(train_sampler)}ê°œ, ê²€ì¦ {len(val_sampler)}ê°œ ë°°ì¹˜")
        
        # ì–¼ë¦¬ ìŠ¤íƒ‘ ë³€ìˆ˜ë“¤
        best_val_loss = float('inf')
        patience_counter = 0
        best_model_state = None
        
        train_loss_history = []
        val_loss_history = []
        train_mae_history = []
        val_mae_history = []

        for epoch in range(EPOCHS):
            # í›ˆë ¨ ë‹¨ê³„
            self.model.train()
            train_loss = train_mae = batch_count = 0
            
            for features, labels in train_dataloader:
                features = features.to(self.device)
                labels = labels.squeeze().to(self.device)
                
                optimizer.zero_grad()
                bpm_pred, _ = self.model(features, None)
                
                # SNR + PSD + ê·¹ë‹¨ BPM ê°€ì¤‘ì¹˜ ì ìš©
                pred = bpm_pred.squeeze()
                labels_squeezed = labels.squeeze()

                # ì°¨ì› ì¼ì¹˜ ë³´ì¥ (ë¸Œë¡œë“œìºìŠ¤íŠ¸ ê²½ê³  ì œê±°)
                pred_flat = pred.view(-1)        # (B,)
                labels_flat = labels_squeezed.view(-1)    # (B,)
                
                # SmoothL1Loss ì§ì ‘ í˜¸ì¶œë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ê²½ê³  ì œê±°
                base = F.smooth_l1_loss(pred_flat, labels_flat, reduction='none', beta=beta_std)  # (B,) í˜•íƒœì˜ ê°œë³„ ìƒ˜í”Œ loss

                # SNR ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚° (ì±„ë„ 3: SNR_hr)
                snr = features[:, :, 3, :].mean(dim=(1,2))  # (B,) - ë°°ì¹˜ë³„ í‰ê·  SNR
                snr_w = (snr - snr.median()) / (snr.std() + 1e-6)
                snr_w = snr_w.clamp(-1, 2) * 0.2 + 1.0  # 0.8~1.4 ë²”ìœ„

                # PSD ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚° (ì±„ë„ 6: PSD_conf)
                psd_conf = features[:, :, 6, :].mean(dim=(1,2))  # (B,) - ë°°ì¹˜ë³„ í‰ê·  PSD ì‹ ë¢°ë„
                psd_w = 0.5 + 0.5 * psd_conf  # 0.5~1.0 ë²”ìœ„ (ì‹ ë¢°ë„ê°€ ë†’ì„ìˆ˜ë¡ ê°€ì¤‘ì¹˜ ì¦ê°€)

                # ì‹¤ì œ BPMìœ¼ë¡œ ë³€í™˜í•˜ì—¬ BPM ê°€ì¤‘ì¹˜ ê³„ì‚°
                true_bpm = labels * self.label_std + self.label_mean
                bpm_w = torch.ones_like(true_bpm)
                bpm_w = bpm_w + 0.6 * (true_bpm < 75).float() + 0.2 * (true_bpm > 95).float()

                # ===== ë¶€ë“œëŸ¬ì›€ ì œì•½ ì¶”ê°€ (z-score ìŠ¤ì¼€ì¼ í†µì¼) =====
                # ë¼ë²¨ê³¼ ê°™ì€ z-score ìŠ¤ì¼€ì¼ì—ì„œ ë¶€ë“œëŸ¬ì›€ ì œì•½ ê³„ì‚°
                if pred.shape[0] > 1:  # ë°°ì¹˜ì— ì—¬ëŸ¬ ìƒ˜í”Œì´ ìˆëŠ” ê²½ìš°ë§Œ
                    # z-score ìŠ¤ì¼€ì¼ì—ì„œ ì—°ì† ì˜ˆì¸¡ê°’ë“¤ì˜ ì°¨ì´ ê³„ì‚°
                    diff = pred[1:] - pred[:-1]  # predëŠ” ì´ë¯¸ z-score ì •ê·œí™”ëœ ê°’
                    smooth_loss = torch.abs(diff).mean()  # L1 ë…¸ë¦„
                else:
                    smooth_loss = torch.tensor(0.0, device=pred.device)

                # ìµœì¢… ê²°í•© ê°€ì¤‘ì¹˜ (ë¸Œë¡œë“œìºìŠ¤íŠ¸ ë²„ê·¸ ìˆ˜ì •)
                # ëª¨ë“  ê°€ì¤‘ì¹˜ë¥¼ (B,) í˜•íƒœë¡œ ìœ ì§€í•´ì„œ element-wise ê³±
                snr_w = snr_w.view(-1)      # (B,) í™•ì‹¤íˆ ë³´ì¥
                psd_w = psd_w.view(-1)      # (B,) í™•ì‹¤íˆ ë³´ì¥
                bpm_w = bpm_w.view(-1)      # (B,) í™•ì‹¤íˆ ë³´ì¥

                combined_w = bpm_w * snr_w * psd_w   # (B,), element-wise ê³±
                base = base.view(-1)   # baseë„ (B,) í™•ì‹¤íˆ ë³´ì¥

                data_loss = (combined_w * base).mean()

                # ===== 2) data_loss, combined_w, base ë¶„í¬ í™•ì¸ =====
                if epoch == 0 and batch_count < 1:
                    print("=== ì†ì‹¤ êµ¬ì„± ìš”ì†Œ ë¶„ì„ ===")
                    print(f"base mean/std: {base.mean().item():.4f}, {base.std().item():.4f}")
                    print(f"combined_w mean/std: {combined_w.mean().item():.4f}, {combined_w.std().item():.4f}")
                    print(f"data_loss: {data_loss.item():.4f}")

                # ë¶€ë“œëŸ¬ì›€ ì œì•½ ê²°í•©
                loss = data_loss + SMOOTH_LAMBDA * smooth_loss

                # ===== 1) ê·¸ë˜ë””ì–¸íŠ¸/íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ í™•ì¸ =====
                if epoch == 0 and batch_count < 1:
                    # íŒŒë¼ë¯¸í„° ë…¸ë¦„ ì €ì¥ (ì—…ë°ì´íŠ¸ ì „)
                    before_norm = sum(p.data.norm().item() for p in self.model.parameters() if p.requires_grad)
                    print(f"before_step_norm: {before_norm:.4f}")

                loss.backward()

                # ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„ ê³„ì‚°
                if epoch == 0 and batch_count < 1:
                    total_grad_norm = 0.0
                    for p in self.model.parameters():
                        if p.grad is not None:
                            total_grad_norm += float(p.grad.data.norm().cpu().item())
                    print(f"grad norm: {total_grad_norm:.4f}")

                optimizer.step()

                # íŒŒë¼ë¯¸í„° ë…¸ë¦„ ë³€í™” í™•ì¸
                if epoch == 0 and batch_count < 1:
                    after_norm = sum(p.data.norm().item() for p in self.model.parameters() if p.requires_grad)
                    param_diff = abs(after_norm - before_norm)
                    print(f"after_step_norm: {after_norm:.4f}, param_diff: {param_diff:.4f}")

                # ë””ë²„ê¹…: ì˜ˆì¸¡ê°’ ë¶„í¬ ë¶„ì„ (ì²« ì—í¬í¬ë§Œ)
                if epoch == 0 and batch_count < 1:
                    print(f"[ë¶€ë“œëŸ¬ì›€] ë°ì´í„° ì†ì‹¤: {data_loss.item():.3f}, ë¶€ë“œëŸ¬ì›€ ì†ì‹¤(L2,z-score): {smooth_loss.item():.3f}, Î»: {SMOOTH_LAMBDA}")
                    print(f"[ë¶€ë“œëŸ¬ì›€] ë°°ì¹˜ í¬ê¸°: {pred.shape[0]}, ë¶€ë“œëŸ¬ì›€ ì ìš©: {'ì˜ˆ' if pred.shape[0] > 1 else 'ì•„ë‹ˆì˜¤'}")

                    # ì˜ˆì¸¡ê°’ ë¶„í¬ ë¶„ì„
                    pred_mean = pred.mean().item()
                    pred_std = pred.std().item()
                    pred_min = pred.min().item()
                    pred_max = pred.max().item()
                    print(f"[ì˜ˆì¸¡ ë¶„í¬] z-score: í‰ê· ={pred_mean:.3f}, í‘œì¤€í¸ì°¨={pred_std:.3f}, ë²”ìœ„=[{pred_min:.3f}, {pred_max:.3f}]")

                    # ë¼ë²¨ ë¶„í¬ ë¶„ì„
                    labels_mean = labels.mean().item()
                    labels_std = labels.std().item()
                    labels_min = labels.min().item()
                    labels_max = labels.max().item()
                    print(f"[ë¼ë²¨ ë¶„í¬] z-score: í‰ê· ={labels_mean:.3f}, í‘œì¤€í¸ì°¨={labels_std:.3f}, ë²”ìœ„=[{labels_min:.3f}, {labels_max:.3f}]")

                    print(f"[ë¼ë²¨ ì •ê·œí™”] mean: {self.label_mean:.3f}, std: {self.label_std:.3f}")
                # MAEëŠ” BPM ë‹¨ìœ„ë¡œ ê³„ì‚° (ì—­ì •ê·œí™”)
                if (self.label_mean is not None) and (self.label_std is not None):
                    pred_bpm = bpm_pred.squeeze() * self.label_std + self.label_mean
                    true_bpm = labels * self.label_std + self.label_mean
                    mae = F.l1_loss(pred_bpm, true_bpm)

                    # BPM ë‹¨ìœ„ ì˜ˆì¸¡ê°’ ë¶„í¬ë„ ë¶„ì„ (ì²« ì—í¬í¬ë§Œ)
                    if epoch == 0 and batch_count < 1:
                        pred_bpm_mean = pred_bpm.mean().item()
                        pred_bpm_std = pred_bpm.std().item()
                        pred_bpm_min = pred_bpm.min().item()
                        pred_bpm_max = pred_bpm.max().item()
                        print(f"[ì˜ˆì¸¡ ë¶„í¬] BPM: í‰ê· ={pred_bpm_mean:.1f}, í‘œì¤€í¸ì°¨={pred_bpm_std:.1f}, ë²”ìœ„=[{pred_bpm_min:.1f}, {pred_bpm_max:.1f}]")

                        true_bpm_mean = true_bpm.mean().item()
                        true_bpm_std = true_bpm.std().item()
                        true_bpm_min = true_bpm.min().item()
                        true_bpm_max = true_bpm.max().item()
                        print(f"[ì‹¤ì œ ë¶„í¬] BPM: í‰ê· ={true_bpm_mean:.1f}, í‘œì¤€í¸ì°¨={true_bpm_std:.1f}, ë²”ìœ„=[{true_bpm_min:.1f}, {true_bpm_max:.1f}]")
                else:
                    mae = F.l1_loss(bpm_pred.squeeze(), labels)
                
                train_loss += loss.item()
                train_mae += mae.item()
                batch_count += 1
            
            avg_train_loss = train_loss / max(1, batch_count)
            avg_train_mae = train_mae / max(1, batch_count)
            
            # ê²€ì¦ ë‹¨ê³„
            self.model.eval()
            val_loss = val_mae = val_batch_count = 0
            
            with torch.no_grad():
                for features, labels in val_dataloader:
                    features = features.to(self.device)
                    labels = labels.to(self.device)
                    
                    bpm_pred, _ = self.model(features, None)
                    
                    # ===== ê²€ì¦ ë‹¨ê³„: ìˆœìˆ˜ ë°ì´í„° ì†ì‹¤ë§Œ ê³„ì‚° (ë¶€ë“œëŸ¬ì›€ ì œì•½ ì œì™¸) =====
                    # ê²€ì¦ì—ì„œëŠ” ëª¨ë¸ í•™ìŠµì´ ì¼ì–´ë‚˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë¶€ë“œëŸ¬ì›€ ì œì•½ ì œì™¸
                    pred_val = bpm_pred.squeeze()  # ì˜ˆì¸¡ê°’
                    labels_val = labels.squeeze()  # ë¼ë²¨

                    # ì°¨ì› ì¼ì¹˜ ë³´ì¥ (ë¸Œë¡œë“œìºìŠ¤íŠ¸ ê²½ê³  ì œê±°)
                    pred_val_flat = pred_val.view(-1)        # (B,)
                    labels_val_flat = labels_val.view(-1)    # (B,)
                    
                    # SmoothL1Loss ì§ì ‘ í˜¸ì¶œë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ê²½ê³  ì œê±°
                    base_loss = F.smooth_l1_loss(pred_val_flat, labels_val_flat, reduction='mean', beta=beta_std)  # ìŠ¤ì¹¼ë¼ ì†ì‹¤

                    # ìµœì¢… ê²€ì¦ ì†ì‹¤ (ë¶€ë“œëŸ¬ì›€ ì œì•½ ì œì™¸)
                    loss = base_loss

                    # ë””ë²„ê¹…: ê²€ì¦ ë‹¨ê³„ ìˆœìˆ˜ ë°ì´í„° ì†ì‹¤ ì¶œë ¥ (ì²« ë°°ì¹˜ë§Œ)
                    if batch_count == 0:
                        print(f"[ê²€ì¦] ìˆœìˆ˜ ë°ì´í„° ì†ì‹¤: {loss:.3f} (ë¶€ë“œëŸ¬ì›€ ì œì•½ ì œì™¸)")
                    # MAEëŠ” BPM ë‹¨ìœ„ë¡œ ê³„ì‚° (ì—­ì •ê·œí™”)
                    if (self.label_mean is not None) and (self.label_std is not None):
                        pred_bpm = bpm_pred.squeeze() * self.label_std + self.label_mean
                        true_bpm = labels * self.label_std + self.label_mean
                        mae = F.l1_loss(pred_bpm, true_bpm)
                    else:
                        mae = F.l1_loss(bpm_pred.squeeze(), labels)
                    
                    val_loss += loss.item()
                    val_mae += mae.item()
                    val_batch_count += 1
            
            avg_val_loss = val_loss / max(1, val_batch_count)
            avg_val_mae = val_mae / max(1, val_batch_count)
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ìŠ¤í… (ê²€ì¦ ì†ì‹¤ ê¸°ë°˜)
            old_lr = optimizer.param_groups[0]['lr']
            scheduler.step(avg_val_loss)
            current_lr = optimizer.param_groups[0]['lr']
            
            # í•™ìŠµë¥  ë³€ê²½ ê°ì§€ ë° ì¶œë ¥
            if current_lr != old_lr:
                print(f"ğŸ”½ í•™ìŠµë¥  ê°ì†Œ: {old_lr:.2e} â†’ {current_lr:.2e}")
            
            # ì–¼ë¦¬ ìŠ¤íƒ‘ ì²´í¬
            if avg_val_loss < best_val_loss - EARLY_STOP_MIN_DELTA:
                best_val_loss = avg_val_loss
                patience_counter = 0
                best_model_state = self.model.state_dict().copy()
                print(f"Epoch {epoch+1}/{EPOCHS} | í›ˆë ¨ Loss: {avg_train_loss:.6f} MAE: {avg_train_mae:.4f} | ê²€ì¦ Loss: {avg_val_loss:.6f} MAE: {avg_val_mae:.4f} | LR: {current_lr:.2e} | ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥!")
            else:
                patience_counter += 1
                if (epoch + 1) % 50 == 0:
                    print(f"Epoch {epoch+1}/{EPOCHS} | í›ˆë ¨ Loss: {avg_train_loss:.6f} MAE: {avg_train_mae:.4f} | ê²€ì¦ Loss: {avg_val_loss:.6f} MAE: {avg_val_mae:.4f} | LR: {current_lr:.2e} | ì¸ë‚´ì‹¬: {patience_counter}/{EARLY_STOP_PATIENCE}")
            
            # ì–¼ë¦¬ ìŠ¤íƒ‘ ì¡°ê±´ í™•ì¸
            if patience_counter >= EARLY_STOP_PATIENCE:
                print(f"\n\n!!! ì–¼ë¦¬ ìŠ¤íƒ‘! {EARLY_STOP_PATIENCE} ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìŒ")
                print(f"ìµœê³  ê²€ì¦ Loss: {best_val_loss:.6f} (Epoch {epoch+1-EARLY_STOP_PATIENCE})")
                break
            
            train_loss_history.append(avg_train_loss)
            val_loss_history.append(avg_val_loss)
            train_mae_history.append(avg_train_mae)
            val_mae_history.append(avg_val_mae)
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ë³µì›
        if best_model_state is not None:
            self.model.load_state_dict(best_model_state)
            print(f"ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ë³µì› ì™„ë£Œ (ê²€ì¦ Loss: {best_val_loss:.6f})")
        
        # ëª¨ë¸ ì €ì¥
        os.makedirs("checkpoints", exist_ok=True)
        torch.save(self.model.state_dict(), "checkpoints/bpm_regressor.pt")
        print("\nëª¨ë¸ ì €ì¥ ì™„ë£Œ: checkpoints/bpm_regressor.pt")

        # í•™ìŠµ ê³¼ì • ì‹œê°í™”
        plot_training_curves(train_loss_history, val_loss_history, train_mae_history, val_mae_history)
    
    def _predict_windows(self, z_tau: np.ndarray) -> List[float]:
        """ìœˆë„ìš°ë³„ BPM ì˜ˆì¸¡ (ê³µí†µ í•¨ìˆ˜)"""
        self.model.eval()
        predictions = []
        
        with torch.no_grad():
            for i in range(WIN_FRAMES, len(z_tau), HOP_FRAMES):
                window = z_tau[i-WIN_FRAMES:i]
                features = self.process_window(window)
                x = torch.FloatTensor(features).unsqueeze(0).to(self.device)
                
                bpm_pred, _ = self.model(x, None)
                y = bpm_pred.cpu().item()
                # ì—­ì •ê·œí™”(ë¼ë²¨ ì •ê·œí™”ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°)
                if (self.label_mean is not None) and (self.label_std is not None):
                    y = y * self.label_std + self.label_mean
                predictions.append(y)
                
        return predictions
    
    def predict_bpm(self, z_tau: np.ndarray) -> Tuple[List[float], List[float]]:
        """BPM ì˜ˆì¸¡ (ì‹œê°„ ì •ë³´ í¬í•¨)"""
        predictions = self._predict_windows(z_tau)
        times = [i / FS for i in range(WIN_FRAMES, len(z_tau), HOP_FRAMES)][:len(predictions)]
        return predictions, times
    
    def calculate_epoch_metrics(self, z_tau: np.ndarray, gt_times: np.ndarray) -> Dict:
        """ì—í¬í¬ë³„ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"""
        
        # ì˜ˆì¸¡ BPM
        pred_bpms = self._predict_windows(z_tau)
        
        # ì •ë‹µ BPM (ì´ë¯¸ ì‹¤ì œ BPM ê°’) - ì°½ ê²½ê³„ í¸í–¥ ì œê±°ëœ ê³„ì‚°
        true_bpms = create_bpm_labels(gt_times, z_tau, WIN_FRAMES, HOP_FRAMES, FRAME_REPETITION_TIME_S, 3.0)
        
        if len(pred_bpms) == 0 or len(true_bpms) == 0:
            return {"rmse": 0.0, "mae": 0.0, "avg_pred_bpm": 0.0, "avg_true_bpm": 0.0}
        
        # ê¸¸ì´ ë§ì¶¤ ë° ë©”íŠ¸ë¦­ ê³„ì‚°
        min_len = min(len(pred_bpms), len(true_bpms))
        pred_array = np.array(pred_bpms[:min_len])
        true_array = np.array(true_bpms[:min_len])
        
        # í›ˆë ¨/ê²€ì¦ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ MAE ê³„ì‚° (PyTorch F.l1_loss ì‚¬ìš©)
        pred_tensor = torch.tensor(pred_array, dtype=torch.float32)
        true_tensor = torch.tensor(true_array, dtype=torch.float32)
        
        # ì°¨ì› ì¼ì¹˜ ë³´ì¥ (ë¸Œë¡œë“œìºìŠ¤íŠ¸ ê²½ê³  ì œê±°)
        pred_flat = pred_tensor.view(-1)        # (N,)
        true_flat = true_tensor.view(-1)        # (N,)
        
        # F.l1_lossë¡œ MAE ê³„ì‚° (í›ˆë ¨/ê²€ì¦ê³¼ ë™ì¼)
        mae_tensor = F.l1_loss(pred_flat, true_flat, reduction='mean')
        
        return {
            "rmse": float(np.sqrt(np.mean((pred_array - true_array) ** 2))),
            "mae": float(mae_tensor.item()),  # PyTorch F.l1_loss ì‚¬ìš©
            "avg_pred_bpm": float(np.mean(pred_array)),
            "avg_true_bpm": float(np.mean(true_array))
        }
    
    def evaluate_predictions(self, z_tau: np.ndarray, gt_times: np.ndarray) -> None:
        """ì˜ˆì¸¡ ì„±ëŠ¥ì„ êµ¬ê°„ë³„ë¡œ ìƒì„¸ í‰ê°€"""
 
        pred_bpms, window_times = self.predict_bpm(z_tau)
        window_sec = WIN_FRAMES * FRAME_REPETITION_TIME_S  # 8ì´ˆ ì°½
        true_bpms = create_bpm_labels(gt_times, z_tau, WIN_FRAMES, HOP_FRAMES, FRAME_REPETITION_TIME_S, window_sec)
        
        # ê¸¸ì´ ë§ì¶¤
        min_len = min(len(pred_bpms), len(true_bpms))
        pred_bpms = pred_bpms[:min_len]
        true_bpms = true_bpms[:min_len]
        window_times = window_times[:min_len]
        
        print(f"\n=== êµ¬ê°„ë³„ BPM ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€ ===")
        
        # ì›í•˜ëŠ” êµ¬ê°„ ê¸¸ì´(ì´ˆ)ì™€ í˜„ì¬ í™‰ ê°„ê²©ìœ¼ë¡œë¶€í„° êµ¬ê°„ ë‹¹ ìœˆë„ìš° ê°œìˆ˜ ê³„ì‚°
        target_interval_sec = 4
        step_seconds = HOP_FRAMES / FS  # 0.5ì´ˆ
        total_duration = len(z_tau) / FS
        interval_size = max(1, int(round(target_interval_sec / step_seconds)))
        for start_idx in range(0, len(pred_bpms), interval_size):
            end_idx = min(start_idx + interval_size, len(pred_bpms))
            
            interval_pred = pred_bpms[start_idx:end_idx]
            interval_true = true_bpms[start_idx:end_idx]
            interval_times = window_times[start_idx:end_idx]
            
            if len(interval_pred) == 0:
                continue
                
            # êµ¬ê°„ ë‚´ í†µê³„ (í›ˆë ¨/ê²€ì¦ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ MAE ê³„ì‚°)
            pred_mean = float(np.mean(interval_pred))
            true_mean = float(np.mean(interval_true))
            pred_std = float(np.std(interval_pred))
            true_std = float(np.std(interval_true))
            
            # PyTorch F.l1_lossë¡œ MAE ê³„ì‚° (í›ˆë ¨/ê²€ì¦ê³¼ ë™ì¼)
            pred_tensor = torch.tensor(interval_pred, dtype=torch.float32)
            true_tensor = torch.tensor(interval_true, dtype=torch.float32)
            pred_flat = pred_tensor.view(-1)
            true_flat = true_tensor.view(-1)
            mae = float(F.l1_loss(pred_flat, true_flat, reduction='mean').item())
            
            rmse = float(np.sqrt(np.mean((np.array(interval_pred) - np.array(interval_true))**2)))
            
            start_time = float(interval_times[0])
            end_time = float(interval_times[-1])
            # ë§ˆì§€ë§‰ êµ¬ê°„ì€ ì‹¤ì œ ì´ ê¸¸ì´ë¥¼ ë°˜ì˜í•´ í‘œì‹œ (ì˜ˆ: 60.0ì´ˆ)
            if end_idx == len(pred_bpms):
                end_time = min(end_time + step_seconds, total_duration)
            
            # í•œ ì¤„ ìš”ì•½ ì¶œë ¥ (MAE ì¶”ê°€)
            print(f"êµ¬ê°„ {start_time:.1f}~{end_time:.1f}ì´ˆ | ì˜ˆì¸¡ {pred_mean:.2f}Â±{pred_std:.2f} | ì‹¤ì œ {true_mean:.2f}Â±{true_std:.2f} | RMSE {rmse:.2f} BPM | MAE {mae:.2f} BPM")
            # print()
    
    def test_on_multiple_files(self, test_data_dir: str, test_answer_dir: str):
        """ì—¬ëŸ¬ í…ŒìŠ¤íŠ¸ íŒŒì¼ë¡œ í‰ê°€"""
        test_pairs = find_matching_files(test_data_dir, test_answer_dir)
        
        if not test_pairs:
            print("í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\n=== í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€ ({len(test_pairs)}ê°œ íŒŒì¼) ===")
        
        all_rmse = []
        all_mae = []
        test_losses = []
        test_maes = []
        
        for i, (test_data_path, test_answer_path) in enumerate(test_pairs):
            file_num = os.path.splitext(os.path.basename(test_data_path))[0]
            print(f"\níŒŒì¼ {file_num} í…ŒìŠ¤íŠ¸:")
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì§ì ‘ ë¡œë”©
            fc_bin, test_z_tau = calculation(test_data_path, FS_ADC, NUM_SAMPLES, PAD_FT, B_HZ)
            test_gt_times = load_ground_truth(test_answer_path)
            
            if test_gt_times is not None:
                # ì„±ëŠ¥ ê³„ì‚°
                metrics = self.calculate_epoch_metrics(test_z_tau, test_gt_times)
                
                print(f"  RMSE: {metrics['rmse']:.2f} BPM")
                print(f"  MAE: {metrics['mae']:.2f} BPM")
                print(f"  ì˜ˆì¸¡ í‰ê· : {metrics['avg_pred_bpm']:.2f}")
                print(f"  ì‹¤ì œ í‰ê· : {metrics['avg_true_bpm']:.2f}")
                
                # êµ¬ê°„ë³„ ìƒì„¸ í‰ê°€ ì¶”ê°€
                self.evaluate_predictions(test_z_tau, test_gt_times)
                
                all_rmse.append(metrics['rmse'])
                all_mae.append(metrics['mae'])
                
                # í…ŒìŠ¤íŠ¸ loss ê³„ì‚° (Huber Loss ì‚¬ìš©)
                test_loss = self.calculate_test_loss(test_z_tau, test_gt_times)
                test_losses.append(test_loss)
                test_maes.append(metrics['mae'])
            else:
                print(f"  âš ï¸ ì •ë‹µ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨")
        
        # ì „ì²´ í‰ê·  ì„±ëŠ¥
        if all_rmse:
            avg_rmse = np.mean(all_rmse)
            avg_mae = np.mean(all_mae)
            std_rmse = np.std(all_rmse)
            std_mae = np.std(all_mae)
            
            print(f"\n=== ì „ì²´ í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ===")
            print(f"í‰ê·  RMSE: {avg_rmse:.2f} Â± {std_rmse:.2f} BPM")
            print(f"í‰ê·  MAE: {avg_mae:.2f} Â± {std_mae:.2f} BPM")
            print(f"í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆ˜: {len(all_rmse)}ê°œ")
            
            # í…ŒìŠ¤íŠ¸ì…‹ loss ê·¸ë˜í”„ ìƒì„±
            if test_losses:
                plot_test_results(test_losses, test_maes, all_rmse)
    
    def run(self, test_data_dir=None, test_answer_dir=None, batch_size=64):  # ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¦ê°€ (ê³¼ì í•© ë°©ì§€)
        """ì „ì²´ ì‹¤í–‰"""
        # 1. ëª¨ë“  í•™ìŠµ ë°ì´í„° ë¡œë”©
        all_z_tau, all_gt_times = self.load_all_training_data()
        
        # 2. ë‹¤ì¤‘ íŒŒì¼ ë°°ì¹˜ í•™ìŠµ
        self.train_on_multiple_files(all_z_tau, all_gt_times, batch_size)
        
        # 3. í…ŒìŠ¤íŠ¸ (ì˜µì…˜)
        if test_data_dir and test_answer_dir:
            self.test_on_multiple_files(test_data_dir, test_answer_dir)
        else:
            print("\nğŸ’¡ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   ì‚¬ìš©ë²•: predictor.run(test_data_dir='path/to/test/', test_answer_dir='path/to/test_answer/')")
    
    def calculate_test_loss(self, z_tau: np.ndarray, gt_times: np.ndarray) -> float:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ loss ê³„ì‚°"""
        self.model.eval()
        total_loss = 0.0
        count = 0
        
        # Huber Loss ì‚¬ìš© (í›ˆë ¨ê³¼ ë™ì¼í•œ beta, ê°œë³„ ìƒ˜í”Œ loss)
        beta_std = 3.0 / self.label_std if self.label_std else 3.0
        # criterion ê°ì²´ëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (F.smooth_l1_loss ì§ì ‘ í˜¸ì¶œ)
        
        with torch.no_grad():
            for i in range(WIN_FRAMES, len(z_tau), HOP_FRAMES):
                window = z_tau[i-WIN_FRAMES:i]
                features = self.process_window(window)
                x = torch.FloatTensor(features).unsqueeze(0).to(self.device)
                
                bpm_pred, _ = self.model(x, None)
                
                # ì •ë‹µ BPM ê³„ì‚°
                t_end = i * FRAME_REPETITION_TIME_S
                t_start = max(0.0, t_end - 3.0)
                m = (gt_times >= t_start) & (gt_times < t_end)
                beats = gt_times[m]
                
                if len(beats) >= 2:
                    ibi = np.diff(beats)
                    true_bpm = 60.0 / float(np.mean(ibi))
                    
                    # ë¼ë²¨ ì •ê·œí™” ì ìš©
                    if self.label_mean is not None and self.label_std is not None:
                        true_bpm_normalized = (true_bpm - self.label_mean) / self.label_std
                        
                        # ì°¨ì› ì¼ì¹˜ ë³´ì¥ (ë¸Œë¡œë“œìºìŠ¤íŠ¸ ê²½ê³  ì œê±°)
                        pred_flat = bpm_pred.squeeze().view(-1)        # (1,)
                        target_flat = torch.tensor(true_bpm_normalized).to(self.device).view(-1)    # (1,)
                        
                        # SmoothL1Loss ì§ì ‘ í˜¸ì¶œë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ê²½ê³  ì œê±°
                        loss = F.smooth_l1_loss(pred_flat, target_flat, reduction='mean', beta=beta_std)
                        total_loss += loss.item()
                        count += 1
        
        return total_loss / max(1, count)
    


if __name__ == "__main__":
    # ë””ë ‰í„°ë¦¬ ê¸°ë°˜ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸
    predictor = BPMPredictor(TRAIN_DATA_DIR, TRAIN_ANSWER_DIR)
    predictor.run(test_data_dir=TEST_DATA_DIR, test_answer_dir=TEST_ANSWER_DIR)
